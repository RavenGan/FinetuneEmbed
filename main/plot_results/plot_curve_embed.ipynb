{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/david/Desktop/FinetuneEmbed')\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# Specify the working directory\n",
    "os.chdir('/Users/david/Desktop/FinetuneEmbed')\n",
    "# os.chdir('/afs/crc.nd.edu/group/StatDataMine/dm011/Dailin_Gan/FinetuneEmbed')\n",
    "llm_ls = ['GenePT_1536',\n",
    "          'GIST-small-Embedding-v0',\n",
    "          'NoInstruct-small-Embedding-v0',\n",
    "          'stella-base-en-v2',\n",
    "          'e5-small-v2',\n",
    "          'GIST-all-MiniLM-L6-v2',\n",
    "          'gte-small',\n",
    "          'bge-small-en-v1.5',\n",
    "          'MedEmbed-small-v0.1',\n",
    "          'gte-tiny',\n",
    "          'e5-small',\n",
    "          # \"biobert-base-cased-v1.1\"\n",
    "          ]\n",
    "random_states = list(range(41, 51)) # set up the random seeds\n",
    "task_ls = ['long_vs_shortTF', 'DosageSensitivity', 'MethylationState/bivalent_vs_lys4',\n",
    "           'MethylationState/bivalent_vs_no_methyl']\n",
    "\n",
    "SLLMs_root = './res/2025_0526_11SLLMs_4tasks'\n",
    "GenePT_root = './res/2025_0527_GenePT_4tasks'\n",
    "embed_type = 'name_embedding'\n",
    "do_cv = \"CV\"\n",
    "do_trun = \"NoTruncation\"\n",
    "fig_num = \"Fig5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all model runs dictionary\n",
    "all_model_runs = {}\n",
    "for task in task_ls:\n",
    "    task_dict = {}\n",
    "    for classifier in ['LR', 'RF']:\n",
    "        classifier_dict = {}\n",
    "        for llm in llm_ls:\n",
    "            runs = []\n",
    "            for state in random_states:\n",
    "                \n",
    "                if do_cv == \"CV\":\n",
    "                    pkl_file = f\"{classifier}_CV_roc_data.pkl\"\n",
    "                elif do_cv == \"NoCV\":\n",
    "                    pkl_file = f\"{classifier}_roc_data.pkl\"\n",
    "                \n",
    "                if llm == 'GenePT_1536':\n",
    "                    res_path = f\"{GenePT_root}/NoPCA_{do_cv}_{embed_type}_{do_trun}/{task}/{llm}/random_state_{state}/{pkl_file}\"\n",
    "                else:\n",
    "                    res_path = f\"{SLLMs_root}/NoPCA_{do_cv}_{embed_type}_{do_trun}/{task}/{llm}/random_state_{state}/{pkl_file}\"\n",
    "                with open(res_path, 'rb') as f:\n",
    "                    run = pickle.load(f)\n",
    "                runs.append(run)\n",
    "            if llm == 'GenePT_1536':\n",
    "                classifier_dict[\"OpenAI\"] = runs # change the naming\n",
    "            else:\n",
    "                classifier_dict[llm] = runs\n",
    "        task_dict[classifier] = classifier_dict\n",
    "    if task == 'long_vs_shortTF':\n",
    "        all_model_runs['Task_1'] = task_dict\n",
    "    elif task == 'DosageSensitivity':\n",
    "        all_model_runs['Task_2'] = task_dict\n",
    "    elif task == 'MethylationState/bivalent_vs_lys4':\n",
    "        all_model_runs['Task_3'] = task_dict\n",
    "    elif task == 'MethylationState/bivalent_vs_no_methyl':\n",
    "        all_model_runs['Task_4'] = task_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Common FPR grid for interpolation\n",
    "fpr_common = np.linspace(0, 1, 100)\n",
    "\n",
    "# Set up 2 rows (classifiers) x 4 columns (tasks)\n",
    "fig, axes = plt.subplots(2, 4, figsize=(22, 12), sharex=True, sharey=True)\n",
    "axes = np.array(axes)\n",
    "\n",
    "# Sort keys for consistent layout\n",
    "tasks_sorted = sorted(all_model_runs.keys())\n",
    "classifiers_sorted = sorted(next(iter(all_model_runs.values())).keys())\n",
    "\n",
    "# Loop over classifiers (rows), tasks (columns)\n",
    "for i_clf, clf in enumerate(classifiers_sorted):\n",
    "    for i_task, task in enumerate(tasks_sorted):\n",
    "        ax = axes[i_clf, i_task]\n",
    "        model_runs = all_model_runs[task][clf]  # model_name -> [runs]\n",
    "\n",
    "        for model_name, runs in model_runs.items():\n",
    "            tpr_macro_all = []\n",
    "            auc_macro_all = []\n",
    "\n",
    "            for run in runs:\n",
    "                y_test_bin = run[\"y_test_bin\"]\n",
    "                y_test_proba = run[\"y_test_proba\"]\n",
    "\n",
    "                # Ensure 2D shape for binary case\n",
    "                if y_test_bin.ndim == 1 or y_test_bin.shape[1] == 1:\n",
    "                    y_test_bin = np.vstack((1 - y_test_bin, y_test_bin)).T\n",
    "                if y_test_proba.ndim == 1 or y_test_proba.shape[1] == 1:\n",
    "                    y_test_proba = np.vstack((1 - y_test_proba, y_test_proba)).T\n",
    "\n",
    "                n_classes = y_test_proba.shape[1]\n",
    "                tpr_per_class = []\n",
    "                aucs = []\n",
    "\n",
    "                for i in range(n_classes):\n",
    "                    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_test_proba[:, i])\n",
    "                    tpr_interp = np.interp(fpr_common, fpr, tpr)\n",
    "                    tpr_interp[0] = 0.0\n",
    "                    tpr_per_class.append(tpr_interp)\n",
    "                    aucs.append(auc(fpr, tpr))\n",
    "\n",
    "                tpr_macro = np.mean(tpr_per_class, axis=0)\n",
    "                auc_macro = np.mean(aucs)\n",
    "                tpr_macro_all.append(tpr_macro)\n",
    "                auc_macro_all.append(auc_macro)\n",
    "\n",
    "            # Plot the mean ROC curve for this model\n",
    "            mean_tpr = np.mean(tpr_macro_all, axis=0)\n",
    "            mean_auc = np.mean(auc_macro_all)\n",
    "            ax.plot(fpr_common, mean_tpr, label=f\"{model_name} (AUC = {mean_auc:.3f})\")\n",
    "\n",
    "        ax.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "        ax.set_title(f\"{task} - {clf}\", fontsize=12)\n",
    "        ax.set_xlabel(\"False Positive Rate\")\n",
    "        ax.set_ylabel(\"True Positive Rate\")\n",
    "        ax.grid(True)\n",
    "\n",
    "        # âœ… Add individual legend for this subplot\n",
    "        ax.legend(fontsize=8, loc=\"lower right\", ncol=1)\n",
    "\n",
    "# Global figure settings\n",
    "# fig.suptitle(\"Mean Macro-Average ROC Curves by Task and Classifier\", fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Save to PDF\n",
    "plt.savefig(f\"./res/2025_0606_AUCPlots/{fig_num}_{do_cv}_{embed_type}_roc_curve.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinetuneBERT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
