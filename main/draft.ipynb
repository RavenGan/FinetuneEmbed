{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/envs/FinetuneBERT/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "# Specify the working directory\n",
    "os.chdir('/Users/david/Desktop/FinetuneEmbed')\n",
    "# os.chdir('/afs/crc.nd.edu/group/StatDataMine/dm011/Dailin_Gan/FinetuneEmbed')\n",
    "\n",
    "from mod.mod_text import *\n",
    "\n",
    "data_dir = \"./data/long_vs_shortTF\"\n",
    "save_csv_dir = \"./res/2024_1125/LongShortTF/long_vs_shortTF_finetune_auc.csv\"\n",
    "output_path = \"./res/2024_1125/LongShortTF/LongShortTF_model_\"\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "val_auc_ls = []\n",
    "test_auc_ls = []\n",
    "\n",
    "random_states = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/envs/FinetuneBERT/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                \n",
      " 20%|â–ˆâ–‰        | 51/260 [00:13<02:02,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6847690343856812, 'eval_AUC': 0.5427350427350427, 'eval_runtime': 1.4584, 'eval_samples_per_second': 23.998, 'eval_steps_per_second': 3.428, 'epoch': 3.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 101/260 [00:21<00:31,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5700475573539734, 'eval_AUC': 0.561965811965812, 'eval_runtime': 0.1595, 'eval_samples_per_second': 219.436, 'eval_steps_per_second': 31.348, 'epoch': 7.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 151/260 [00:28<00:20,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5978271961212158, 'eval_AUC': 0.5662393162393162, 'eval_runtime': 0.1511, 'eval_samples_per_second': 231.629, 'eval_steps_per_second': 33.09, 'epoch': 11.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 201/260 [00:36<00:11,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5712093710899353, 'eval_AUC': 0.5149572649572649, 'eval_runtime': 0.1654, 'eval_samples_per_second': 211.616, 'eval_steps_per_second': 30.231, 'epoch': 15.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 251/260 [00:43<00:01,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5705122947692871, 'eval_AUC': 0.6517094017094017, 'eval_runtime': 0.1717, 'eval_samples_per_second': 203.807, 'eval_steps_per_second': 29.115, 'epoch': 19.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 260/260 [00:45<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 45.4412, 'train_samples_per_second': 45.773, 'train_steps_per_second': 5.722, 'train_loss': 0.6098667438213642, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 41.73it/s]\n",
      "/Users/david/anaconda3/envs/FinetuneBERT/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Validation AUC: 0.5149572649572649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [00:53<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 53.2165, 'train_samples_per_second': 52.239, 'train_steps_per_second': 6.765, 'train_loss': 0.8557342529296875, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 46.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.5106837606837606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/envs/FinetuneBERT/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 19%|â–ˆâ–‰        | 50/260 [00:07<00:30,  6.79it/s]\n",
      " 20%|â–ˆâ–‰        | 51/260 [00:07<00:41,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5720748901367188, 'eval_AUC': 0.6517094017094017, 'eval_runtime': 0.1557, 'eval_samples_per_second': 224.81, 'eval_steps_per_second': 32.116, 'epoch': 3.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 100/260 [00:15<00:24,  6.66it/s]\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 101/260 [00:15<00:32,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5701310634613037, 'eval_AUC': 0.6068376068376068, 'eval_runtime': 0.1661, 'eval_samples_per_second': 210.711, 'eval_steps_per_second': 30.102, 'epoch': 7.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 150/260 [00:22<00:16,  6.80it/s]\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 151/260 [00:22<00:21,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5773085355758667, 'eval_AUC': 0.6047008547008548, 'eval_runtime': 0.153, 'eval_samples_per_second': 228.745, 'eval_steps_per_second': 32.678, 'epoch': 11.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 200/260 [00:30<00:08,  6.75it/s]\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 201/260 [00:30<00:11,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5701779127120972, 'eval_AUC': 0.6025641025641025, 'eval_runtime': 0.1602, 'eval_samples_per_second': 218.54, 'eval_steps_per_second': 31.22, 'epoch': 15.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 250/260 [00:37<00:01,  6.60it/s]\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 251/260 [00:38<00:01,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.570619523525238, 'eval_AUC': 0.6025641025641025, 'eval_runtime': 0.1758, 'eval_samples_per_second': 199.077, 'eval_steps_per_second': 28.44, 'epoch': 19.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 260/260 [00:39<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 39.8978, 'train_samples_per_second': 52.133, 'train_steps_per_second': 6.517, 'train_loss': 0.6033476022573617, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 50.48it/s]\n",
      "/Users/david/anaconda3/envs/FinetuneBERT/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Validation AUC: 0.5918803418803419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [00:52<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 52.9358, 'train_samples_per_second': 52.516, 'train_steps_per_second': 6.801, 'train_loss': 0.8581428527832031, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 46.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.4444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for random_state in random_states:\n",
    "    output_dir = output_path  + str(random_state)\n",
    "\n",
    "    train_dir = data_dir + \"/TrainEvalTestData/train_data_\" + str(random_state) + \".pkl\"\n",
    "    eva_dir = data_dir + \"/TrainEvalTestData/eval_data_\" + str(random_state) + \".pkl\"\n",
    "    test_dir = data_dir + \"/TrainEvalTestData/test_data_\" + str(random_state) + \".pkl\"\n",
    "\n",
    "    # prepare the input data\n",
    "    with open(train_dir, \"rb\") as f:\n",
    "        train_data = pickle.load(f)\n",
    "    with open(eva_dir, \"rb\") as f:\n",
    "        eval_data = pickle.load(f)\n",
    "    with open(test_dir, \"rb\") as f:\n",
    "        test_data = pickle.load(f)\n",
    "        \n",
    "    val_auc_scores = []\n",
    "    \n",
    "    train_texts, train_labels = train_data['desc'], train_data['labels']\n",
    "    eval_texts, eval_labels = eval_data['desc'], eval_data['labels']\n",
    "    test_texts, test_labels = test_data['desc'], test_data['labels']\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    mod_dir, val_auc = one_fold_training(train_texts, train_labels, eval_texts, eval_labels, \n",
    "                                     tokenizer, output_dir, 0, model_name)\n",
    "    \n",
    "    val_auc_scores.append(val_auc)\n",
    "\n",
    "    # locate the best model\n",
    "    best_fold_idx = np.argmax(val_auc_scores)\n",
    "    best_model_dir = output_dir + '/fold_' + str(best_fold_idx + 1)\n",
    "    best_model = AutoModelForSequenceClassification.from_pretrained(best_model_dir)\n",
    "\n",
    "    # create the training data for final training\n",
    "    train_texts_all = train_texts + eval_texts\n",
    "    train_labels_all = train_labels + eval_labels\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    full_train_dataset = TextDataset(train_texts_all, train_labels_all, tokenizer)\n",
    "\n",
    "    # Fine-tune the best model on the full training data\n",
    "    output_dir = output_dir + \"/final_model\"\n",
    "    final_trainer = finetune_best_mod(full_train_dataset, best_model, output_dir)\n",
    "\n",
    "    # Evaluate the best model on the test set\n",
    "    test_dataset = TextDataset(test_texts, test_labels, tokenizer)\n",
    "    test_auc = pred_test(final_trainer, test_dataset)\n",
    "\n",
    "    # save the results\n",
    "    val_auc_ls.append(f\"{val_auc:.4f}\")\n",
    "    test_auc_ls.append(f\"{test_auc:.4f}\")\n",
    "    rows = zip(val_auc_ls, test_auc_ls)\n",
    "    # Write to a CSV file\n",
    "    with open(save_csv_dir, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Optional: Write a header row\n",
    "        writer.writerow(['val_auc', 'test_auc'])\n",
    "        # Write the rows\n",
    "        writer.writerows(rows)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinetuneBERT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
