{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "os.chdir('/Users/david/Desktop/FinetuneEmbed')\n",
    "from mod.mod_text import *\n",
    "\n",
    "data_dir = \"./data/long_vs_shortTF\"\n",
    "save_csv_dir = \"./res/2024_1125/LongShortTF/long_vs_shortTF_finetune_auc.csv\"\n",
    "output_path = \"./res/2024_1125/LongShortTF/LongShortTF_model_\"\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "mean_val_auc_ls = []\n",
    "test_auc_ls = []\n",
    "\n",
    "random_states = list(range(41, 51)) # set up the random seeds\n",
    "random_states = [1, 2]\n",
    "random_state = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = output_path  + str(random_state)\n",
    "\n",
    "\n",
    "train_dir = data_dir + \"/TrainEvalTestData/train_data_\" + str(random_state) + \".pkl\"\n",
    "eva_dir = data_dir + \"/TrainEvalTestData/eval_data_\" + str(random_state) + \".pkl\"\n",
    "test_dir = data_dir + \"/TrainEvalTestData/test_data_\" + str(random_state) + \".pkl\"\n",
    "\n",
    "# prepare the input data\n",
    "with open(train_dir, \"rb\") as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open(eva_dir, \"rb\") as f:\n",
    "    eval_data = pickle.load(f)\n",
    "with open(test_dir, \"rb\") as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "val_auc_scores = []\n",
    "output_dirs = []  # Track output directories for each fold\n",
    "\n",
    "train_texts, train_labels = train_data['desc'], train_data['labels']\n",
    "eval_texts, eval_labels = eval_data['desc'], eval_data['labels']\n",
    "test_texts, test_labels = test_data['desc'], test_data['labels']\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/envs/FinetuneBERT/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  5%|â–Œ         | 13/260 [00:02<00:36,  6.73it/s]\n",
      "  5%|â–Œ         | 13/260 [00:02<00:36,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5997536778450012, 'eval_AUC': 0.3504273504273504, 'eval_runtime': 0.1597, 'eval_samples_per_second': 219.198, 'eval_steps_per_second': 31.314, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 26/260 [00:04<00:35,  6.67it/s]\n",
      " 10%|â–ˆ         | 26/260 [00:04<00:35,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5722935199737549, 'eval_AUC': 0.36752136752136755, 'eval_runtime': 0.1566, 'eval_samples_per_second': 223.562, 'eval_steps_per_second': 31.937, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 39/260 [00:07<00:33,  6.52it/s]\n",
      " 15%|â–ˆâ–Œ        | 39/260 [00:07<00:33,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6076807379722595, 'eval_AUC': 0.31196581196581197, 'eval_runtime': 0.146, 'eval_samples_per_second': 239.744, 'eval_steps_per_second': 34.249, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 52/260 [00:09<00:31,  6.56it/s]\n",
      " 20%|â–ˆâ–ˆ        | 52/260 [00:10<00:31,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6234163045883179, 'eval_AUC': 0.37606837606837606, 'eval_runtime': 0.1592, 'eval_samples_per_second': 219.793, 'eval_steps_per_second': 31.399, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 65/260 [00:12<00:29,  6.71it/s]\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 65/260 [00:12<00:29,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6945410966873169, 'eval_AUC': 0.41452991452991456, 'eval_runtime': 0.1436, 'eval_samples_per_second': 243.694, 'eval_steps_per_second': 34.813, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 78/260 [00:15<00:27,  6.73it/s]\n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 78/260 [00:15<00:27,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8522564172744751, 'eval_AUC': 0.4230769230769231, 'eval_runtime': 0.1861, 'eval_samples_per_second': 188.087, 'eval_steps_per_second': 26.87, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 91/260 [00:17<00:25,  6.66it/s]\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 91/260 [00:17<00:25,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0859893560409546, 'eval_AUC': 0.45726495726495725, 'eval_runtime': 0.1564, 'eval_samples_per_second': 223.734, 'eval_steps_per_second': 31.962, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 104/260 [00:20<00:24,  6.31it/s]\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 104/260 [00:20<00:24,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9290553331375122, 'eval_AUC': 0.47435897435897434, 'eval_runtime': 0.1641, 'eval_samples_per_second': 213.332, 'eval_steps_per_second': 30.476, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 117/260 [00:22<00:21,  6.61it/s]\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 117/260 [00:23<00:21,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1776615381240845, 'eval_AUC': 0.44871794871794873, 'eval_runtime': 0.1508, 'eval_samples_per_second': 232.083, 'eval_steps_per_second': 33.155, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 130/260 [00:25<00:19,  6.62it/s]\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 130/260 [00:25<00:19,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2473260164260864, 'eval_AUC': 0.44017094017094016, 'eval_runtime': 0.1635, 'eval_samples_per_second': 214.038, 'eval_steps_per_second': 30.577, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 143/260 [00:28<00:17,  6.60it/s]\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 143/260 [00:28<00:17,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.383251428604126, 'eval_AUC': 0.45726495726495725, 'eval_runtime': 0.1576, 'eval_samples_per_second': 222.091, 'eval_steps_per_second': 31.727, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 156/260 [00:30<00:15,  6.72it/s]\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 156/260 [00:30<00:15,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.371849775314331, 'eval_AUC': 0.46153846153846156, 'eval_runtime': 0.1422, 'eval_samples_per_second': 246.069, 'eval_steps_per_second': 35.153, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 169/260 [00:33<00:13,  6.67it/s]\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 169/260 [00:33<00:13,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6445518732070923, 'eval_AUC': 0.423076923076923, 'eval_runtime': 0.1718, 'eval_samples_per_second': 203.743, 'eval_steps_per_second': 29.106, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 169/260 [00:34<00:18,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 34.1591, 'train_samples_per_second': 60.891, 'train_steps_per_second': 7.611, 'train_loss': 0.3730248445589867, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 52.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Validation AUC: 0.47435897435897434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mod_dir, val_auc = one_fold_training(train_texts, train_labels, eval_texts, eval_labels, \n",
    "                                     tokenizer, output_dir, 0, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_auc_scores.append(val_auc)\n",
    "output_dirs.append(mod_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate the best model\n",
    "best_fold_idx = np.argmax(val_auc_scores)\n",
    "best_model_dir = output_dir + '/fold_' + str(best_fold_idx + 1)\n",
    "best_model = AutoModelForSequenceClassification.from_pretrained(best_model_dir)\n",
    "\n",
    "# create the training data for final training\n",
    "train_texts_all = train_texts + eval_texts\n",
    "train_labels_all = train_labels + eval_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/envs/FinetuneBERT/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:14<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 14.2582, 'train_samples_per_second': 48.744, 'train_steps_per_second': 6.312, 'train_loss': 0.32301436530219185, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 48.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.7264957264957266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "full_train_dataset = TextDataset(train_texts_all, train_labels_all, tokenizer)\n",
    "\n",
    "# Fine-tune the best model on the full training data\n",
    "output_dir = output_dir + \"/final_model\"\n",
    "final_trainer = finetune_best_mod(full_train_dataset, best_model, output_dir)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_dataset = TextDataset(test_texts, test_labels, tokenizer)\n",
    "test_auc = pred_test(final_trainer, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinetuneBERT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
