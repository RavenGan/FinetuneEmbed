{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/envs/FinetuneBERT/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/david/Desktop/FinetuneEmbed')\n",
    "# sys.path.append('/afs/crc.nd.edu/group/StatDataMine/dm011/Dailin_Gan/FinetuneEmbed')\n",
    "\n",
    "# Specify the working directory\n",
    "os.chdir('/Users/david/Desktop/FinetuneEmbed')\n",
    "# os.chdir('/afs/crc.nd.edu/group/StatDataMine/dm011/Dailin_Gan/FinetuneEmbed')\n",
    "from mod.multi_mod import *\n",
    "\n",
    "random_states = list(range(41, 43)) # set up the random seeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"dmis-lab/biobert-base-cased-v1.1\",\n",
    "               'avsolatorio/NoInstruct-small-Embedding-v0']\n",
    "\n",
    "save_mod_names = [\"biobert-base-cased-v1.1\",\n",
    "                  'NoInstruct-small-Embedding-v0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters found:  {'C': 1, 'penalty': 'l1'}\n",
      "ROC data saved to: ./res/2025_0525/long_vs_shortTF/biobert-base-cased-v1.1/random_state_41/LR_CV_roc_data.pkl\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/envs/FinetuneBERT/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found:  {'max_depth': None, 'n_estimators': 100}\n",
      "Saved ROC data to ./res/2025_0525/long_vs_shortTF/biobert-base-cased-v1.1/random_state_41/RF_CV_roc_data.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/envs/FinetuneBERT/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters found:  {'C': 10, 'penalty': 'l2'}\n",
      "ROC data saved to: ./res/2025_0525/long_vs_shortTF/biobert-base-cased-v1.1/random_state_42/LR_CV_roc_data.pkl\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best hyperparameters found:  {'max_depth': 20, 'n_estimators': 100}\n",
      "Saved ROC data to ./res/2025_0525/long_vs_shortTF/biobert-base-cased-v1.1/random_state_42/RF_CV_roc_data.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/envs/FinetuneBERT/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters found:  {'C': 100, 'penalty': 'l2'}\n",
      "ROC data saved to: ./res/2025_0525/long_vs_shortTF/NoInstruct-small-Embedding-v0/random_state_41/LR_CV_roc_data.pkl\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best hyperparameters found:  {'max_depth': 30, 'n_estimators': 50}\n",
      "Saved ROC data to ./res/2025_0525/long_vs_shortTF/NoInstruct-small-Embedding-v0/random_state_41/RF_CV_roc_data.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/envs/FinetuneBERT/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters found:  {'C': 1, 'penalty': 'l2'}\n",
      "ROC data saved to: ./res/2025_0525/long_vs_shortTF/NoInstruct-small-Embedding-v0/random_state_42/LR_CV_roc_data.pkl\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best hyperparameters found:  {'max_depth': None, 'n_estimators': 200}\n",
      "Saved ROC data to ./res/2025_0525/long_vs_shortTF/NoInstruct-small-Embedding-v0/random_state_42/RF_CV_roc_data.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/envs/FinetuneBERT/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "do_cv = True\n",
    "\n",
    "for i in range(len(model_names)):\n",
    "     model_name = model_names[i]\n",
    "     save_mod_name = save_mod_names[i]\n",
    "\n",
    "     ## Long- vs short- range TFs\n",
    "     # The input data used here are downloaded from Chen et al. (2020) \n",
    "     # (link: https://www-nature-com.stanford.idm.oclc.org/articles/s41467-020-16106-x).\n",
    "     data_dir = \"./data/long_vs_shortTF/TrainEvalTestData\"\n",
    "     save_csv_dir = \"./res/2025_0525/\" + save_mod_name + \"_long_vs_shortTF_NumRes.csv\"\n",
    "     ROC_save_dir = \"./res/2025_0525/long_vs_shortTF/\" + save_mod_name + \"/\"\n",
    "\n",
    "     smallmod_multiple_run_TrainTest(data_dir, save_csv_dir, random_states, model_name, do_cv,\n",
    "                                     ROC_save_dir, do_pca=False, n_PCs=384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_cv = True\n",
    "model_name = model_names[0]\n",
    "save_mod_name = save_mod_names[0]\n",
    "\n",
    "random_state = random_states[0]\n",
    "do_pca=False\n",
    "n_PCs=384\n",
    "\n",
    "data_dir = \"./data/long_vs_shortTF/TrainEvalTestData\"\n",
    "save_csv_dir = \"./res/2025_0525/\" + save_mod_name + \"_long_vs_shortTF_NumRes.csv\"\n",
    "ROC_save_dir = \"./res/2025_0525/long_vs_shortTF/\" + save_mod_name + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = data_dir + \"/train_data_\" + str(random_state) + \".pkl\"\n",
    "eval_dir = data_dir + \"/eval_data_\" + str(random_state) + \".pkl\"\n",
    "test_dir = data_dir + \"/test_data_\" + str(random_state) + \".pkl\"\n",
    "# prepare the input data\n",
    "with open(train_dir, \"rb\") as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open(eval_dir, \"rb\") as f:\n",
    "    eval_data = pickle.load(f)\n",
    "with open(test_dir, \"rb\") as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "ROC_save_path = ROC_save_dir\n",
    "\n",
    "ROC_save_path = ROC_save_path + \"random_state_\" + str(random_state)\n",
    "\n",
    "train_dict = train_data\n",
    "eval_dict = eval_data\n",
    "test_dict = test_data\n",
    "\n",
    "train_text = train_dict['desc']\n",
    "train_labels = train_dict['labels']\n",
    "\n",
    "eval_text = eval_dict['desc']\n",
    "eval_labels = eval_dict['labels']\n",
    "\n",
    "test_text = test_dict['desc']\n",
    "test_labels = test_dict['labels']\n",
    "\n",
    "# Combine the training and validation data\n",
    "train_text = train_text + eval_text\n",
    "train_labels = train_labels + eval_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_text), len(train_labels), len(test_text), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train_text\n",
    "\n",
    "model.eval()\n",
    "\n",
    "if isinstance(text, str):\n",
    "    text = [text]\n",
    "\n",
    "inp = tokenizer(text, return_tensors=\"pt\", padding=True, \n",
    "                truncation=True, max_length=512)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = outputs.last_hidden_state.mean(dim=1)  # shape: (batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "X_train = get_BioBERT_Embedding(model, tokenizer, train_text)\n",
    "X_train = np.array(X_train)\n",
    "X_test = get_BioBERT_Embedding(model, tokenizer, test_text)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_data_smallmod(train_dict, \n",
    "                                                      eval_dict, \n",
    "                                                      test_dict, \n",
    "                                                      model_name,\n",
    "                                                      do_pca, n_PCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_cv = True\n",
    "\n",
    "for i in range(len(model_names)):\n",
    "     model_name = model_names[i]\n",
    "     save_mod_name = save_mod_names[i]\n",
    "\n",
    "     ## Long- vs short- range TFs\n",
    "     # The input data used here are downloaded from Chen et al. (2020) \n",
    "     # (link: https://www-nature-com.stanford.idm.oclc.org/articles/s41467-020-16106-x).\n",
    "     data_dir = \"./data/long_vs_shortTF/TrainEvalTestData\"\n",
    "     save_csv_dir = \"./res/2025_0525/\" + save_mod_name + \"_long_vs_shortTF_NumRes.csv\"\n",
    "     ROC_save_dir = \"./res/2025_0525/long_vs_shortTF/\" + save_mod_name + \"/\"\n",
    "\n",
    "     smallmod_multiple_run_TrainTest(data_dir, save_csv_dir, random_states, model_name, do_cv,\n",
    "                                     ROC_save_dir, do_pca=False, n_PCs=384)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinetuneBERT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
